{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "from IPython import display\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community import embeddings\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference.model.base` to set default model name\n"
     ]
    }
   ],
   "source": [
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=\"C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\dogs.pdf\",\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    extract_image_block_output_dir=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "text_elements = []\n",
    "table_elements = []\n",
    "\n",
    "text_summaries = []\n",
    "table_summaries = []\n",
    "\n",
    "summary_prompt = \"\"\"\n",
    "Summarize the following {element_type}:\n",
    "{element}\n",
    "\"\"\"\n",
    "summary_chain = LLMChain(\n",
    "    llm=ChatOllama(model=\"mistral\",temperature=0),\n",
    "    prompt=PromptTemplate.from_template(summary_prompt)\n",
    ")\n",
    "\n",
    "for e in raw_pdf_elements:\n",
    "    if 'CompositeElement' in repr(e):\n",
    "        text_elements.append(e.text)\n",
    "        summary = summary_chain.run({'element_type': 'text', 'element': e})\n",
    "        text_summaries.append(summary)\n",
    "\n",
    "    elif 'Table' in repr(e):\n",
    "        table_elements.append(e.text)\n",
    "        summary = summary_chain.run({'element_type': 'table', 'element': e})\n",
    "        table_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dogs”).\\n\\nQuestions? Email us at CenterforAnimalWelfare@aphis.usda.gov\\n\\nThe U.S. lepartment of A; ulture is an equal opportunity provider, employer, and lender.\\n\\nAnimal Care Animal and Plant Health Inspection Service AC-18-004 ¢ Issued June 2018'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_elements[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image summaries\n",
    "image_elements = []\n",
    "image_summaries = []\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "def summarize_image(encoded_image):\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"You are a bot that is good at analyzing images related to Dog's health.\"),\n",
    "        HumanMessage(content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Describe the contents of this image.\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:images/jpeg;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ])\n",
    "    ]\n",
    "    response = ChatOllama(model=\"llava\",temperature=0).invoke(prompt)\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only string image_url content parts are supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m encoded_image \u001b[38;5;241m=\u001b[39m encode_image(image_path)\n\u001b[0;32m      5\u001b[0m image_elements\u001b[38;5;241m.\u001b[39mappend(encoded_image)\n\u001b[1;32m----> 6\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_image\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m image_summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n",
      "Cell \u001b[1;32mIn[36], line 25\u001b[0m, in \u001b[0;36msummarize_image\u001b[1;34m(encoded_image)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_image\u001b[39m(encoded_image):\n\u001b[0;32m     10\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m         SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a bot that is good at analyzing images related to Dog\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms health.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m         HumanMessage(content\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         ])\n\u001b[0;32m     24\u001b[0m     ]\n\u001b[1;32m---> 25\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mChatOllama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllava\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:154\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    150\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    151\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    153\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 154\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    163\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:554\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    548\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    552\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    553\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    414\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    416\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    417\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    419\u001b[0m ]\n\u001b[0;32m    420\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:405\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 405\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m         )\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 624\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:257\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    235\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    239\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    265\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    266\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:188\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    187\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:159\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    154\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    155\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    157\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    158\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_messages_to_ollama_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    160\u001b[0m     }\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    162\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload, stop\u001b[38;5;241m=\u001b[39mstop, api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    163\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Barani\\Desktop\\chatbot\\multimodel\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:132\u001b[0m, in \u001b[0;36mChatOllama._convert_messages_to_ollama_messages\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    130\u001b[0m             images\u001b[38;5;241m.\u001b[39mappend(image_url_components[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly string image_url \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent parts are supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         )\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported message content type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust either have type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m field.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Only string image_url content parts are supported."
     ]
    }
   ],
   "source": [
    "for i in os.listdir(output_path):\n",
    "    if i.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(output_path, i)\n",
    "        encoded_image = encode_image(image_path)\n",
    "        image_elements.append(encoded_image)\n",
    "        summary = summarize_image(encoded_image[0])\n",
    "        image_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_elements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
