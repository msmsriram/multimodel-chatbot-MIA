{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema.runnable import RunnablePassthrough\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.schema.output_parser import StrOutputParser\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# template = \"\"\"describe the following image\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# model = ChatOllama(model=\"llava\",temperature=0)\n",
    "\n",
    "# chain = ( prompt\n",
    "#     | model\n",
    "#     | StrOutputParser()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(\"describe this image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "# res=ollama.chat(\n",
    "#     model=\"llava\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             'role':'user',\n",
    "#             'content':'Describe this image :',\n",
    "#             'images':['C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\figures\\\\figure-19-12.jpg']\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(res['message']['content'])\n",
    "import os\n",
    "import ollama\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "image_summary = []\n",
    "\n",
    "# Define the directory path\n",
    "dir_path = \"C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\figures\"\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    # Check if the file is a .jpg file\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        \n",
    "        # Call the chat function with the image file\n",
    "        res = ollama.chat(\n",
    "            model=\"llava\",\n",
    "            messages=[\n",
    "                {\n",
    "                    'role':'user',\n",
    "                    'content':'Describe this image :',\n",
    "                    'images':[file_path]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Append the result to the image_summary list\n",
    "        image_summary.append(res['message']['content'])\n",
    "\n",
    "# Print the image_summary list\n",
    "len(image_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The image is a meme that features a photograph of cooked chicken pieces arranged to resemble a map, with various continents outlined. Above the photo of the chicken pieces, there\\'s a text that reads: \"Sometimes I just look at pictures of the earth from space and I marvel at how beautiful it all is.\" The meme plays on the idea that food, in this case, chicken nuggets, can be creatively arranged to mimic the Earth. This creative arrangement is meant to be humorous, as it\\'s an unexpected way to present food. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The image shows a screenshot of a computer interface with a humorous message. The central focus is a pop-up window displaying a conversation in what appears to be the \"My Life\" channel on Twitch, which is a live streaming service. In this chat, there\\'s a reference to a \"lolcow,\" but instead of the expected image, it says, \"My life is a lolcow.\" This is likely meant to be a joke about the creator\\'s personal situation, suggesting that their life is chaotic and amusing in a self-deprecating way.\\n\\nOn the left side of the interface, there are two pop-up windows from different websites or applications. One appears to be an image from \"My Joke Website,\" which shows a simple webpage with a single joke written on it. The other pop-up is from \"Punniest Twitter\" and contains a screenshot of a tweet with the joke mentioned above.\\n\\nOn the right side, there are two more pop-ups: one from \"My Life\" showing a link to \"mylife,\" which seems to be the Twitch channel where the original conversation took place; the other is from \"My Joke Website\" with a similar joke written on it. This suggests that the humor is being shared across different platforms or sites, possibly for comedic effect or as part of an ongoing joke series.\\n\\nThe overall tone of the image is light-hearted and humorous, playing on internet culture references such as \"lolcow\" (a term often used in meme culture to describe someone who is either extremely excited about something or completely losing it) and \"mylife,\" which might imply that someone\\'s personal life is humorously described through the lens of internet memes. '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image you have provided does not contain a person. It appears to be a graphical or abstract image with no recognizable human features. If you have any specific questions about the content of the image, feel free to ask and I will do my best to assist you. \n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# # supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# # class to view the latest available supported parameters\n",
    "# llm = ChatOllama(model=\"llava\")\n",
    "# prompt = ChatPromptTemplate.from_template(\"what is the name of the person in this image {topic}\")\n",
    "\n",
    "# # using LangChain Expressive Language chain syntax\n",
    "# # learn more about the LCEL on\n",
    "# # /docs/expression_language/why\n",
    "# chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# # for brevity, response is printed in terminal\n",
    "# # You can use LangServe to deploy your application for\n",
    "# # production\n",
    "# print(chain.invoke({\"topic\": \"C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\figures\\\\figure-19-12.jpg\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "# res=ollama.chat(\n",
    "#     model=\"llava\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             'role':'user',\n",
    "#             'content':'Describe this image :',\n",
    "#             'images':['C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\figures\\\\figure-19-12.jpg']\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(res['message']['content'])\n",
    "import os\n",
    "import ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "image_summary = []\n",
    "\n",
    "# Define the directory path\n",
    "dir_path = \"C:\\\\Users\\\\Barani\\\\Desktop\\\\chatbot\\\\figures\"\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    # Check if the file is a .jpg file\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        \n",
    "        # Call the chat function with the image file\n",
    "        \n",
    "\n",
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "        llm = ChatOllama(model=\"llava\")\n",
    "        prompt = ChatPromptTemplate.from_template(\"what is the name of the person in this image {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# /docs/expression_language/why\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# for brevity, response is printed in terminal\n",
    "# You can use LangServe to deploy your application for\n",
    "# production\n",
    "        res=chain.invoke({\"topic\": \"{file_path}\"})\n",
    "        \n",
    "        # Append the result to the image_summary list\n",
    "        image_summary.append(res)\n",
    "\n",
    "# Print the image_summary list\n",
    "len(image_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, but I cannot view or access external files. Can you please provide more information about the image or upload it to a file sharing platform so that I can take a look? \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
